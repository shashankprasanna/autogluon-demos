{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/autogluon/lib/python3.7/site-packages/mxnet/optimizer/optimizer.py:167: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "from autogluon import TabularPrediction as task\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  dataset/otto-group-product-classification-challenge.zip\n",
      "replace dataset/sampleSubmission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "dataset = 'dataset'\n",
    "!kaggle competitions download -p {dataset} -q otto-group-product-classification-challenge\n",
    "!unzip -d {dataset} {dataset}/otto-group-product-classification-challenge.zip\n",
    "!rm {dataset}/otto-group-product-classification-challenge.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "autogluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: dataset/train.csv | Columns = 95 / 95 | Rows = 61878 -> 61878\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       1       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       1       0   \n",
       "2       0       0       0       0       0       0       0       1       0   \n",
       "3       1       0       0       1       6       1       5       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_10  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0        0  ...        1        0        0        0        0        0   \n",
       "1        0  ...        0        0        0        0        0        0   \n",
       "2        0  ...        0        0        0        0        0        0   \n",
       "3        1  ...        0        1        2        0        0        0   \n",
       "4        0  ...        1        0        0        0        0        1   \n",
       "\n",
       "   feat_91  feat_92  feat_93   target  \n",
       "0        0        0        0  Class_1  \n",
       "1        0        0        0  Class_1  \n",
       "2        0        0        0  Class_1  \n",
       "3        0        0        0  Class_1  \n",
       "4        0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training time:\n",
    "train_data = task.Dataset(file_path=f'{dataset}/train.csv').drop('id', axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = 'target' # specifies which column do we want to predict\n",
    "savedir = 'otto_models/' # where to save trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to otto_models/\n",
      "Train Data Rows:    61878\n",
      "Train Data Columns: 94\n",
      "Preprocessing data ...\n",
      "Here are the first 10 unique label values in your data:  ['Class_1' 'Class_2' 'Class_3' 'Class_4' 'Class_5' 'Class_6' 'Class_7'\n",
      " 'Class_8' 'Class_9']\n",
      "AutoGluon infers your prediction problem is: multiclass  (because dtype of label-column == object)\n",
      "If this is wrong, please specify `problem_type` argument in fit() instead (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "Feature Generator processed 61878 data points with 93 features\n",
      "Original Features:\n",
      "\tint features: 93\n",
      "Generated Features:\n",
      "\tint features: 0\n",
      "All Features:\n",
      "\tint features: 93\n",
      "\tData preprocessing and feature engineering runtime = 0.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: log_loss\n",
      "This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "To change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: log_loss\n",
      "/home/ubuntu/anaconda3/envs/autogluon/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return _load(spec)\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l0 ...\n",
      "\t-0.5691\t = Validation log_loss score\n",
      "\t27.63s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l0 ...\n",
      "\t-0.5827\t = Validation log_loss score\n",
      "\t30.13s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l0 ...\n",
      "\t-0.5855\t = Validation log_loss score\n",
      "\t39.71s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l0 ...\n",
      "\t-0.6026\t = Validation log_loss score\n",
      "\t37.96s\t = Training runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l0 ...\n",
      "\t-2.4108\t = Validation log_loss score\n",
      "\t139.4s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l0 ...\n",
      "\t-2.4032\t = Validation log_loss score\n",
      "\t146.54s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l0 ...\n",
      "\t-0.4661\t = Validation log_loss score\n",
      "\t319.21s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l0 ...\n",
      "\t-0.471\t = Validation log_loss score\n",
      "\t4102.7s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l0 ...\n",
      "\t-0.5984\t = Validation log_loss score\n",
      "\t423.83s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l0 ...\n",
      "\t-0.4595\t = Validation log_loss score\n",
      "\t774.86s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t-0.442\t = Validation log_loss score\n",
      "\t24.31s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierGini_STACKER_l1 ...\n",
      "\t-0.4721\t = Validation log_loss score\n",
      "\t32.1s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr_STACKER_l1 ...\n",
      "\t-0.4628\t = Validation log_loss score\n",
      "\t41.05s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini_STACKER_l1 ...\n",
      "\t-0.4778\t = Validation log_loss score\n",
      "\t27.16s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr_STACKER_l1 ...\n",
      "\t-0.468\t = Validation log_loss score\n",
      "\t27.74s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif_STACKER_l1 ...\n",
      "\t-2.2507\t = Validation log_loss score\n",
      "\t262.92s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist_STACKER_l1 ...\n",
      "\t-2.2434\t = Validation log_loss score\n",
      "\t264.72s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier_STACKER_l1 ...\n",
      "\t-0.4241\t = Validation log_loss score\n",
      "\t96.03s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier_STACKER_l1 ...\n",
      "\t-0.4246\t = Validation log_loss score\n",
      "\t838.59s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier_STACKER_l1 ...\n",
      "\t-0.46\t = Validation log_loss score\n",
      "\t609.97s\t = Training runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom_STACKER_l1 ...\n",
      "\t-0.4388\t = Validation log_loss score\n",
      "\t429.2s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l2 ...\n",
      "\t-0.416\t = Validation log_loss score\n",
      "\t24.48s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8721.71s ...\n"
     ]
    }
   ],
   "source": [
    "predictor = task.fit(train_data=train_data, \n",
    "                     label=label_column, \n",
    "                     output_directory=savedir, \n",
    "                     eval_metric='log_loss', \n",
    "                     auto_stack=True,\n",
    "                     verbosity=2,\n",
    "                     visualizer='tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Number of models trained: 22\n",
      "Types of models trained: \n",
      "{'WeightedEnsembleModel', 'StackerEnsembleModel'}\n",
      "Validation performance of individual models: {'RandomForestClassifierGini_STACKER_l0': -0.5691089791208548, 'RandomForestClassifierEntr_STACKER_l0': -0.5826890390024927, 'ExtraTreesClassifierGini_STACKER_l0': -0.5855208676626903, 'ExtraTreesClassifierEntr_STACKER_l0': -0.6025590380356861, 'KNeighborsClassifierUnif_STACKER_l0': -2.410849865487888, 'KNeighborsClassifierDist_STACKER_l0': -2.4031890499617976, 'LightGBMClassifier_STACKER_l0': -0.466066913889447, 'CatboostClassifier_STACKER_l0': -0.47099706491836313, 'NeuralNetClassifier_STACKER_l0': -0.5984127911895897, 'LightGBMClassifierCustom_STACKER_l0': -0.4595365541478719, 'weighted_ensemble_k0_l1': -0.4420447748019833, 'RandomForestClassifierGini_STACKER_l1': -0.4720540352120622, 'RandomForestClassifierEntr_STACKER_l1': -0.4627935758444223, 'ExtraTreesClassifierGini_STACKER_l1': -0.4778061258079188, 'ExtraTreesClassifierEntr_STACKER_l1': -0.46800174250007043, 'KNeighborsClassifierUnif_STACKER_l1': -2.2507275986589748, 'KNeighborsClassifierDist_STACKER_l1': -2.2433740435357055, 'LightGBMClassifier_STACKER_l1': -0.4240954689098985, 'CatboostClassifier_STACKER_l1': -0.42459011129338103, 'NeuralNetClassifier_STACKER_l1': -0.4599860812381185, 'LightGBMClassifierCustom_STACKER_l1': -0.438840112073192, 'weighted_ensemble_k0_l2': -0.41598438632498796}\n",
      "Best model (based on validation performance): weighted_ensemble_k0_l2\n",
      "Hyperparameter-tuning used: False\n",
      "Bagging used: True  (with 10 folds)\n",
      "Stack-ensembling used: True  (with 1 levels)\n",
      "User-specified hyperparameters:\n",
      "{'NN': {'num_epochs': 500, 'visualizer': 'tensorboard'}, 'GBM': {'num_boost_round': 10000}, 'CAT': {'iterations': 10000}, 'RF': {'n_estimators': 300}, 'XT': {'n_estimators': 300}, 'KNN': {}, 'custom': ['GBM']}\n",
      "Plot summary of models saved to file: SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary() # display detailed summary of fit() process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = task.load('otto_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: dataset/test.csv | Columns = 94 / 94 | Rows = 144368 -> 144368\n"
     ]
    }
   ],
   "source": [
    "dataset = 'dataset'\n",
    "test_data_full = task.Dataset(file_path=f'{dataset}/test.csv')\n",
    "test_data = test_data_full.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/autogluon/lib/python3.7/imp.py:342: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  return _load(spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13d 7h 4min 2s, sys: 14min 38s, total: 13d 7h 18min 40s\n",
      "Wall time: 3h 36min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pred_probablities = predictor.predict_proba(test_data, as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probablities.insert(loc=0, column='id', value=test_data_full['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27.4M/27.4M [00:02<00:00, 10.4MB/s]\n",
      "Successfully submitted to Otto Group Product Classification Challenge"
     ]
    }
   ],
   "source": [
    "submission_name = f'submission-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}.csv'\n",
    "pred_probablities.to_csv(submission_name,index=False)\n",
    "!kaggle competitions submit otto-group-product-classification-challenge -f {submission_name} -m \"autogluon {submission_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
